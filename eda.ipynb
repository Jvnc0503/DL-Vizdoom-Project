{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3395a7d",
   "metadata": {},
   "source": [
    "# EDA de grabaciones VizDoom\n",
    "Este notebook inspecciona la **estructura y formato** de archivos de grabación: `.npz`, `.parquet`, `.json` y `.mkv`.\n",
    "\n",
    "> Modo muestra por defecto: pocas sesiones y pocos archivos por tipo para evitar salida excesiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49880416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from fastparquet import ParquetFile\n",
    "except Exception:\n",
    "    ParquetFile = None\n",
    "\n",
    "# Configuración de muestra\n",
    "RECORDINGS_PATH = Path(\"recordings\")\n",
    "SESSION = \"session_20260205_194411\"  # None para tomar por muestreo\n",
    "MAX_SESSIONS = 1\n",
    "MAX_FILES_PER_TYPE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7767c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _numeric_stats(arr: np.ndarray) -> str:\n",
    "    if arr.size == 0:\n",
    "        return \"empty\"\n",
    "    if np.issubdtype(arr.dtype, np.number):\n",
    "        return f\"min={arr.min()} max={arr.max()}\"\n",
    "    return \"non-numeric\"\n",
    "\n",
    "\n",
    "def summarize_npz(npz_path: Path) -> dict[str, Any]:\n",
    "    summary: dict[str, Any] = {\"file\": npz_path.name, \"arrays\": []}\n",
    "    with np.load(npz_path, allow_pickle=False) as data:\n",
    "        for key in data.files:\n",
    "            arr = data[key]\n",
    "            summary[\"arrays\"].append(\n",
    "                {\n",
    "                    \"key\": key,\n",
    "                    \"shape\": tuple(arr.shape),\n",
    "                    \"dtype\": str(arr.dtype),\n",
    "                    \"stats\": _numeric_stats(arr),\n",
    "                }\n",
    "            )\n",
    "    return summary\n",
    "\n",
    "\n",
    "def summarize_json(json_path: Path) -> dict[str, Any]:\n",
    "    with json_path.open(\"r\", encoding=\"utf-8\") as file:\n",
    "        payload = json.load(file)\n",
    "\n",
    "    summary: dict[str, Any] = {\n",
    "        \"file\": json_path.name,\n",
    "        \"root_type\": type(payload).__name__,\n",
    "    }\n",
    "\n",
    "    if isinstance(payload, dict):\n",
    "        keys = list(payload.keys())\n",
    "        summary[\"num_keys\"] = len(keys)\n",
    "        summary[\"keys_preview\"] = keys[:15]\n",
    "        summary[\"value_types\"] = {key: type(value).__name__ for key, value in payload.items()}\n",
    "    elif isinstance(payload, list):\n",
    "        summary[\"length\"] = len(payload)\n",
    "        if payload:\n",
    "            summary[\"item_type\"] = type(payload[0]).__name__\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da7ffea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_parquet(parquet_path: Path) -> dict[str, Any]:\n",
    "    summary: dict[str, Any] = {\"file\": parquet_path.name}\n",
    "\n",
    "    if ParquetFile is not None:\n",
    "        pq = ParquetFile(str(parquet_path))\n",
    "        summary[\"rows\"] = int(pq.count())\n",
    "        summary[\"columns\"] = list(pq.columns)\n",
    "        summary[\"num_row_groups\"] = len(pq.row_groups)\n",
    "        summary[\"dtypes\"] = {col: str(dtype) for col, dtype in pq.dtypes.items()}\n",
    "        return summary\n",
    "\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    summary[\"rows\"] = len(df)\n",
    "    summary[\"columns\"] = list(df.columns)\n",
    "    summary[\"dtypes\"] = {col: str(dtype) for col, dtype in df.dtypes.items()}\n",
    "    return summary\n",
    "\n",
    "\n",
    "def summarize_mkv(video_path: Path) -> dict[str, Any]:\n",
    "    summary: dict[str, Any] = {\"file\": video_path.name}\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        summary[\"error\"] = \"No se pudo abrir el video\"\n",
    "        return summary\n",
    "\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = float(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    duration_s = (frame_count / fps) if fps > 0 else None\n",
    "\n",
    "    summary[\"frame_count\"] = frame_count\n",
    "    summary[\"fps\"] = fps\n",
    "    summary[\"resolution\"] = (height, width)\n",
    "    summary[\"duration_s\"] = duration_s\n",
    "\n",
    "    ok, frame = cap.read()\n",
    "    if ok and frame is not None:\n",
    "        summary[\"frame_shape\"] = tuple(frame.shape)\n",
    "        summary[\"frame_dtype\"] = str(frame.dtype)\n",
    "        summary[\"frame_stats\"] = _numeric_stats(frame)\n",
    "    cap.release()\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45d07c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sample_files(files: list[Path], max_files: int) -> tuple[list[Path], int]:\n",
    "    if max_files <= 0:\n",
    "        return files, 0\n",
    "    sampled = files[:max_files]\n",
    "    omitted = max(0, len(files) - len(sampled))\n",
    "    return sampled, omitted\n",
    "\n",
    "\n",
    "def inspect_session(session_path: Path, max_files_per_type: int) -> None:\n",
    "    print(f\"\\n=== SESSION: {session_path.name} ===\")\n",
    "\n",
    "    npz_files = sorted(session_path.glob(\"*.npz\"))\n",
    "    parquet_files = sorted(session_path.glob(\"*.parquet\"))\n",
    "    json_files = sorted(session_path.glob(\"*.json\"))\n",
    "    mkv_files = sorted(session_path.glob(\"*.mkv\"))\n",
    "\n",
    "    print(\n",
    "        f\"Archivos detectados -> npz: {len(npz_files)}, parquet: {len(parquet_files)}, json: {len(json_files)}, mkv: {len(mkv_files)}\"\n",
    "    )\n",
    "\n",
    "    if npz_files:\n",
    "        print(\"\\n[NPZ]\")\n",
    "        npz_sample, npz_omitted = _sample_files(npz_files, max_files_per_type)\n",
    "        for path in npz_sample:\n",
    "            info = summarize_npz(path)\n",
    "            print(f\"- {info['file']}\")\n",
    "            for arr in info[\"arrays\"]:\n",
    "                print(\n",
    "                    f\"  • key={arr['key']} shape={arr['shape']} dtype={arr['dtype']} {arr['stats']}\"\n",
    "                )\n",
    "        if npz_omitted:\n",
    "            print(f\"  • ... ({npz_omitted} archivos NPZ omitidos en la muestra)\")\n",
    "\n",
    "    if parquet_files:\n",
    "        print(\"\\n[PARQUET]\")\n",
    "        parquet_sample, parquet_omitted = _sample_files(parquet_files, max_files_per_type)\n",
    "        for path in parquet_sample:\n",
    "            info = summarize_parquet(path)\n",
    "            print(f\"- {info['file']} | rows={info.get('rows')} | row_groups={info.get('num_row_groups', 'n/a')}\")\n",
    "            print(f\"  • columns: {info.get('columns', [])}\")\n",
    "            print(f\"  • dtypes: {info.get('dtypes', {})}\")\n",
    "        if parquet_omitted:\n",
    "            print(f\"  • ... ({parquet_omitted} archivos Parquet omitidos en la muestra)\")\n",
    "\n",
    "    if json_files:\n",
    "        print(\"\\n[JSON]\")\n",
    "        json_sample, json_omitted = _sample_files(json_files, max_files_per_type)\n",
    "        for path in json_sample:\n",
    "            info = summarize_json(path)\n",
    "            print(f\"- {info['file']} | root={info['root_type']}\")\n",
    "            if \"num_keys\" in info:\n",
    "                print(f\"  • num_keys={info['num_keys']}\")\n",
    "                print(f\"  • keys_preview={info['keys_preview']}\")\n",
    "                print(f\"  • value_types={info['value_types']}\")\n",
    "            if \"length\" in info:\n",
    "                print(f\"  • length={info['length']} item_type={info.get('item_type')}\")\n",
    "        if json_omitted:\n",
    "            print(f\"  • ... ({json_omitted} archivos JSON omitidos en la muestra)\")\n",
    "\n",
    "    if mkv_files:\n",
    "        print(\"\\n[MKV]\")\n",
    "        mkv_sample, mkv_omitted = _sample_files(mkv_files, max_files_per_type)\n",
    "        for path in mkv_sample:\n",
    "            info = summarize_mkv(path)\n",
    "            if \"error\" in info:\n",
    "                print(f\"- {info['file']} | error={info['error']}\")\n",
    "                continue\n",
    "            print(\n",
    "                f\"- {info['file']} | frames={info.get('frame_count')} fps={info.get('fps')} res={info.get('resolution')} duration_s={info.get('duration_s')}\"\n",
    "            )\n",
    "            if \"frame_shape\" in info:\n",
    "                print(\n",
    "                    f\"  • sample_frame shape={info['frame_shape']} dtype={info['frame_dtype']} {info['frame_stats']}\"\n",
    "                )\n",
    "        if mkv_omitted:\n",
    "            print(f\"  • ... ({mkv_omitted} archivos MKV omitidos en la muestra)\")\n",
    "\n",
    "\n",
    "def resolve_sessions(recordings_path: Path, session: str | None, max_sessions: int) -> tuple[list[Path], int]:\n",
    "    if session:\n",
    "        explicit = recordings_path / session\n",
    "        if explicit.exists() and explicit.is_dir():\n",
    "            return [explicit], 0\n",
    "        raise FileNotFoundError(f\"No se encontró la sesión: {explicit}\")\n",
    "\n",
    "    sessions = sorted([entry for entry in recordings_path.iterdir() if entry.is_dir()])\n",
    "    if not sessions:\n",
    "        raise FileNotFoundError(f\"No hay sesiones dentro de: {recordings_path}\")\n",
    "    if max_sessions <= 0:\n",
    "        return sessions, 0\n",
    "    sampled = sessions[:max_sessions]\n",
    "    omitted = max(0, len(sessions) - len(sampled))\n",
    "    return sampled, omitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d15cb1",
   "metadata": {},
   "source": [
    "## Ejecutar inspección\n",
    "Ajusta `SESSION`, `MAX_SESSIONS` o `MAX_FILES_PER_TYPE` en la celda de configuración y luego ejecuta esta celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be48c73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SESSION: session_20260205_194411 ===\n",
      "Archivos detectados -> npz: 22, parquet: 1, json: 1, mkv: 1\n",
      "\n",
      "[NPZ]\n",
      "- depth_chunk_000.npz\n",
      "  • key=frames shape=(350, 240, 320) dtype=uint16 min=0 max=255\n",
      "- depth_chunk_001.npz\n",
      "  • key=frames shape=(350, 240, 320) dtype=uint16 min=0 max=255\n",
      "  • ... (20 archivos NPZ omitidos en la muestra)\n",
      "\n",
      "[PARQUET]\n",
      "- meta.parquet | rows=3735 | row_groups=1\n",
      "  • columns: ['t_index', 'action_bin', 'action_names', 'reward', 'is_terminal', 'is_timeout', 'lives', 'health', 'armor', 'killcount', 'timestamp_s', 'terminal_reason', 'doom_wad', 'doom_map', 'doom_skill', 'selected_weapon', 'selected_weapon_ammo', 'ammo1', 'ammo2', 'ammo3', 'ammo4', 'weapon1', 'weapon2', 'weapon3', 'weapon4', 'weapon5', 'weapon6', 'weapon7', 'cumulative_reward_video']\n",
      "  • dtypes: {'t_index': 'int64', 'action_bin': 'object', 'action_names': 'object', 'reward': 'float64', 'is_terminal': 'bool', 'is_timeout': 'bool', 'lives': 'int64', 'health': 'float64', 'armor': 'float64', 'killcount': 'float64', 'timestamp_s': 'float64', 'terminal_reason': 'object', 'doom_wad': 'object', 'doom_map': 'object', 'doom_skill': 'int64', 'selected_weapon': 'float64', 'selected_weapon_ammo': 'float64', 'ammo1': 'float64', 'ammo2': 'float64', 'ammo3': 'float64', 'ammo4': 'float64', 'weapon1': 'float64', 'weapon2': 'float64', 'weapon3': 'float64', 'weapon4': 'float64', 'weapon5': 'float64', 'weapon6': 'float64', 'weapon7': 'float64', 'cumulative_reward_video': 'float64'}\n",
      "\n",
      "[JSON]\n",
      "- session_meta.json | root=dict\n",
      "  • num_keys=21\n",
      "  • keys_preview=['button_names', 'gamevariable_names', 'num_steps', 'terminal_reason', 'cumulative_reward', 'doom_wad', 'doom_map', 'doom_skill', 'video_backend', 'video_path', 'video_fps', 'video_codec', 'video_crf', 'video_preset', 'chunk_size']\n",
      "  • value_types={'button_names': 'list', 'gamevariable_names': 'list', 'num_steps': 'int', 'terminal_reason': 'str', 'cumulative_reward': 'float', 'doom_wad': 'str', 'doom_map': 'str', 'doom_skill': 'int', 'video_backend': 'str', 'video_path': 'str', 'video_fps': 'float', 'video_codec': 'str', 'video_crf': 'int', 'video_preset': 'str', 'chunk_size': 'int', 'total_steps': 'int', 'buttons': 'list', 'gamevariables': 'list', 'config_path': 'str', 'keymap_path': 'str', 'dataset_format': 'dict'}\n",
      "\n",
      "[MKV]\n",
      "- screen.mkv | frames=3735 fps=35.0 res=(240, 320) duration_s=106.71428571428571\n",
      "  • sample_frame shape=(240, 320, 3) dtype=uint8 min=0 max=255\n"
     ]
    }
   ],
   "source": [
    "if not RECORDINGS_PATH.exists() or not RECORDINGS_PATH.is_dir():\n",
    "    raise FileNotFoundError(f\"No se encontró la carpeta recordings: {RECORDINGS_PATH}\")\n",
    "\n",
    "sessions, omitted_sessions = resolve_sessions(RECORDINGS_PATH, SESSION, MAX_SESSIONS)\n",
    "for session_path in sessions:\n",
    "    inspect_session(session_path, MAX_FILES_PER_TYPE)\n",
    "\n",
    "if omitted_sessions:\n",
    "    print(f\"\\n... ({omitted_sessions} sesiones omitidas en la muestra)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
